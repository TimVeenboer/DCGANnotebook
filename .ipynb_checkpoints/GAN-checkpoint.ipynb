{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYfh_dop2jwH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wU-ybKXEQwJM"
   },
   "outputs": [],
   "source": [
    "# Setting the constants\n",
    "BATCHSIZE, CHANNELS, WIDTH, HEIGHT = 100, 1, 28, 28\n",
    "FAKE, REAL = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSWSU-db2rgc",
    "outputId": "cf0d4a4a-60e2-4e0a-8db5-72c6a6285035"
   },
   "outputs": [],
   "source": [
    "### Downloading the MNIST dataset\n",
    "\n",
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz\n",
    "transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                             ])\n",
    "mnist_set = MNIST(root='./', download=True, transform=transform)\n",
    "dataset = DataLoader(mnist_set, batch_size=BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hIDcRtx5A9_"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Architecture of the discriminator that distinguishes real and generated\n",
    "     images from each other.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(CHANNELS, 32, kernel_size=7, stride=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=8, stride=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 1, kernel_size=8, stride=8)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = F.leaky_relu(output)\n",
    "        output = self.batchnorm1(output)\n",
    "        output = self.conv2(output)\n",
    "        output = F.leaky_relu(output)\n",
    "        output = self.batchnorm2(output)\n",
    "        output = self.conv3(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWPXpfldICp3"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Architecture for the generator. It generates an image based on noise\n",
    "     created from a zero-mean gaussian.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(BATCHSIZE, 512, 4, 1, 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(512)\n",
    "        self.conv2 = nn.ConvTranspose2d(512, 256, 4, 2, 1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "        self.conv3 = nn.ConvTranspose2d(256, 128, 4, 2, 2)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.ConvTranspose2d(128, 64, 4, 1, 1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.ConvTranspose2d(64, 1, 4, 2, 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.batchnorm1(F.relu(self.conv1(input)))\n",
    "        output = self.batchnorm2(F.relu(self.conv2(output)))\n",
    "        output = self.batchnorm3(F.relu(self.conv3(output)))\n",
    "        output = self.batchnorm4(F.relu(self.conv4(output)))\n",
    "        output = torch.tanh(self.conv5(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxfQwDAxRI_R",
    "outputId": "867832a4-20b3-4de2-e314-394e8c80abeb"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "# loss function, binary cross-entropy since we have 0 and 1 as labels\n",
    "bce = nn.BCELoss()\n",
    "optimizerD = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "optimizerG = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "epochs = 7\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataset):\n",
    "        D.zero_grad()\n",
    "        # train the discriminator on real numbers \n",
    "        # create labels for real images\n",
    "        label = torch.full((BATCHSIZE,), REAL, dtype=torch.float, device=device)\n",
    "        # make predictions with the discriminator\n",
    "        predictions = D(data[0].cuda()).to(device).view(-1)\n",
    "        # get and update the gradients with the real labels\n",
    "        realError = bce(predictions, label)\n",
    "        realError.backward()\n",
    "\n",
    "        # train the discriminator on fake generated images\n",
    "        # create the fake labels \n",
    "        label.fill_(FAKE)\n",
    "        # create noise\n",
    "        noise = torch.randn(BATCHSIZE, BATCHSIZE, 1, 1, device=device)\n",
    "        # create a fake image from the noise\n",
    "        fake_images = G(noise).to(device)\n",
    "        # make predictions with the discriminator\n",
    "        predictions = D(fake_images.detach()).to(device).view(-1)\n",
    "        # get and update the gradients with the fake labels\n",
    "        fakeError = bce(predictions, label)\n",
    "        fakeError.backward()\n",
    "        addedError = realError + fakeError\n",
    "        optimizerD.step()\n",
    "\n",
    "        # train the generator \n",
    "        G.zero_grad()\n",
    "        # initialize real labels again\n",
    "        label.fill_(REAL)\n",
    "        # make predictions with the discriminator for the fake images\n",
    "        predictions = D(fake_images).to(device).view(-1)\n",
    "        # train the generator with these predictions and the real labels\n",
    "        generatorError = bce(predictions, label)\n",
    "        generatorError.backward()\n",
    "        optimizerG.step()\n",
    "        print('Samples: {}/60000\\nEpoch: {}\\nLoss D: {}\\nLoss G: {}\\n'.format((i+1)*BATCHSIZE, epoch, addedError, generatorError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKxVYQoytxym"
   },
   "outputs": [],
   "source": [
    "# plot images\n",
    "noise = torch.randn(BATCHSIZE, BATCHSIZE, 1, 1, device=device)\n",
    "images = G(noise).to(device)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(images[64].detach().cpu()[0], cmap='gray')\n",
    "ax2.imshow(images[32].detach().cpu()[0], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
